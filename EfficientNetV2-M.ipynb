{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet V2 M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Compute Capability: (8, 6)\n",
      "‚úÖ Your GPU supports Mixed Precision Training (AMP)!\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA is available! GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "    # Check if the GPU supports mixed precision (AMP)\n",
    "    compute_capability = torch.cuda.get_device_capability(device)\n",
    "    print(f\"Compute Capability: {compute_capability}\")\n",
    "\n",
    "    if compute_capability[0] >= 7:  # Tensor Cores require Compute Capability 7.0+\n",
    "        print(\"‚úÖ Your GPU supports Mixed Precision Training (AMP)!\")\n",
    "    else:\n",
    "        print(\"‚ùå Your GPU does NOT fully support Mixed Precision Training.\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset path and constants\n",
    "data_dir = ''  # Replace with your dataset path\n",
    "num_classes = 3 # Three classes because of only three grades\n",
    "batch_size = 16 # Sets the number of images per batch. High number uses more memory and allows less chances for model to update gradients\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001 # Sets the initial learning rate that causes the model to update gradients.\n",
    "top_k = 3  # For top-k accuracy\n",
    "\n",
    "# Define checkpoint directory\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((480, 480)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=f'{data_dir}/train', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=f'{data_dir}/val', transform=val_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=f'{data_dir}/test', transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet V2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.efficientnet_v2_m(weights='IMAGENET1K_V1')\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Enable Torch 2.0 compilation for faster training\n",
    "model = torch.compile(model)\n",
    "\n",
    "# Define loss function, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation\n",
    "best_val_accuracy = 0.0\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Metrics for plotting\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "top_k_accuracies = []\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save checkpoint\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, best_val_accuracy, filename='checkpoint.pth'):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_val_accuracy': best_val_accuracy,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'top_k_accuracies': top_k_accuracies\n",
    "    }\n",
    "    torch.save(checkpoint, os.path.join(checkpoint_dir, filename))\n",
    "\n",
    "# Function to load checkpoint\n",
    "def load_checkpoint(model, optimizer, scheduler, filename='checkpoint.pth'):\n",
    "    checkpoint = torch.load(os.path.join(checkpoint_dir, filename))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    best_val_accuracy = checkpoint['best_val_accuracy']\n",
    "    train_accuracies = checkpoint['train_accuracies']\n",
    "    val_accuracies = checkpoint['val_accuracies']\n",
    "    top_k_accuracies = checkpoint['top_k_accuracies']\n",
    "    return epoch, best_val_accuracy, train_accuracies, val_accuracies, top_k_accuracies\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, class_names):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    return conf_matrix, accuracy, report\n",
    "\n",
    "def top_k_accuracy(output, target, k=3):\n",
    "    with torch.no_grad():\n",
    "        _, pred = output.topk(k, dim=1)\n",
    "        correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "        return correct.sum().item() / target.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a checkpoint exists and load it\n",
    "checkpoint_filename = 'checkpoint.pth'\n",
    "start_epoch = 0\n",
    "if os.path.exists(os.path.join(checkpoint_dir, checkpoint_filename)):\n",
    "    print(\"Loading checkpoint...\")\n",
    "    start_epoch, best_val_accuracy, train_accuracies, val_accuracies, top_k_accuracies = load_checkpoint(model, optimizer, scheduler, checkpoint_filename)\n",
    "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "# Check if best_model.pth or last_model.pth exists\n",
    "best_model_path = 'best_model.pth'\n",
    "last_model_path = 'last_model.pth'\n",
    "\n",
    "if os.path.exists(best_model_path):\n",
    "    print(\"Loading best model...\")\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print(\"Resuming training from the best model.\")\n",
    "elif os.path.exists(last_model_path):\n",
    "    print(\"Loading last model...\")\n",
    "    model.load_state_dict(torch.load(last_model_path))\n",
    "    print(\"Resuming training from the last model.\")\n",
    "elif os.path.exists(os.path.join(checkpoint_dir, checkpoint_filename)):\n",
    "    print(\"Loading checkpoint...\")\n",
    "    start_epoch, best_val_accuracy, train_accuracies, val_accuracies, top_k_accuracies = load_checkpoint(model, optimizer, scheduler, checkpoint_filename)\n",
    "    print(f\"Resuming training from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"No checkpoint or model found. Starting training from scratch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Validation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables CuDNN benchmarking, which optimizes GPU performance by selecting the fastest convolution algorithms for your model.\n",
    "# Helps if input sizes don‚Äôt change much (like the fixed 480x480 images).\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/efficientnet_v2_m\")\n",
    "\n",
    "# Training and validation loop with checkpoint saving\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    scaler = GradScaler()  # Initialize gradient scaler\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "\n",
    "        # Mixed Precision Training\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        with autocast():  # Enable mixed precision\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Scale gradients to prevent underflow\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # ‚úÖ Prevent exploding gradients\n",
    "        scaler.step(optimizer)  # Update weights\n",
    "        scaler.update()  # Adjust scaling factor\n",
    "\n",
    "        # ‚úÖ Update loss and accuracy tracking\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "    train_accuracies.append(epoch_acc.item())\n",
    "\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # ‚úÖ Log training loss and accuracy to TensorBoard\n",
    "    writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/train\", epoch_acc, epoch)\n",
    "\n",
    "    # ================= Validation ==================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    top_k_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "            top_k_corrects += top_k_accuracy(outputs, labels, k=top_k) * labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_dataset)\n",
    "    val_accuracy = val_corrects.double() / len(val_dataset)\n",
    "    val_top_k_accuracy = top_k_corrects / len(val_dataset)  # ‚úÖ Divide by total validation samples\n",
    "    val_accuracies.append(val_accuracy.item())\n",
    "    top_k_accuracies.append(val_top_k_accuracy)\n",
    "\n",
    "    conf_matrix, accuracy, report = calculate_metrics(all_labels, all_preds, class_names)\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Top-{top_k} Accuracy: {val_top_k_accuracy:.4f}\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # ‚úÖ Log validation loss and accuracy to TensorBoard\n",
    "    writer.add_scalar(\"Loss/val\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/val\", val_accuracy, epoch)\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(\"Saved Best Model\")\n",
    "\n",
    "    # Save checkpoint at the end of each epoch\n",
    "    save_checkpoint(epoch, model, optimizer, scheduler, best_val_accuracy, checkpoint_filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "    torch.save(model.state_dict(), 'last_model.pth')\n",
    "\n",
    "    writer.add_scalar(\"Learning Rate\", optimizer.param_groups[0]['lr'], epoch)  # ‚úÖ Log before LR update\n",
    "    scheduler.step()\n",
    "\n",
    "writer.close()  # ‚úÖ Closes TensorBoard writer\n",
    "\n",
    "# Open terminal and run tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Over Epochs Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "# plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.savefig('train-val-acc.png')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy', marker='s')\n",
    "plt.fill_between(range(1, num_epochs + 1), \n",
    "                 np.array(val_accuracies) - 0.01, \n",
    "                 np.array(val_accuracies) + 0.01, \n",
    "                 color='b', alpha=0.1)  # Shaded variance region\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('train-val-acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top-K Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Top-1 Validation Accuracy', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), top_k_accuracies, label=f'Top-{top_k} Validation Accuracy', marker='s')\n",
    "plt.title('Top-1 and Top-k Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('top-k-accuracy.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix (in number)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.Blues, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion-matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_matrix.sum(axis=1, keepdims=True)\n",
    "row_sums[row_sums == 0] = 1  # ‚úÖ Prevent division by zero\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / row_sums\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Normalize confusion matrix\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(conf_matrix_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix (Normalized)\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion-matrix.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_corrects = 0\n",
    "    all_test_labels = []\n",
    "    all_test_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Evaluating on Test Set\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            all_test_labels.extend(labels.cpu().numpy())\n",
    "            all_test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(test_dataset)\n",
    "    test_accuracy = test_corrects.double() / len(test_dataset)\n",
    "\n",
    "    conf_matrix, accuracy, report = calculate_metrics(all_test_labels, all_test_preds, class_names)\n",
    "\n",
    "    print(f\"\\n‚úÖ Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"üîç Classification Report:\\n\", report)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Test Set Confusion Matrix\")\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('test-confusion-matrix.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on the test set after training\n",
    "evaluate_on_test_set(model, test_loader, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
